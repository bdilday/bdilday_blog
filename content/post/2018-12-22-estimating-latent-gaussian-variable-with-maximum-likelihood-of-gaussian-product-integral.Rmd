---
title: Estimating latent Gaussian variable with maximum likelihood of Gaussian-product
  integral
author: ~
date: '2018-12-22'
slug: estimating-latent-gaussian-variable-with-maximum-likelihood-of-gaussian-product-integral
categories: []
tags: []
---

Suppose we have a population with a Normal distribution of some property, `$t$`, i.e. `$t_i \sim N(\mu, \sigma_t$`. For each member of the population we make a noisy measurement of the value, where the error distribution is Normal, `$\epsilon_i \sim N(0, \sigma_i)$`. The probability to make an observation `$x_i$` is then, 

$$ P(x_i | t) ~ 
\sim
\frac{1}{2 \pi \sigma_i \sigma_t}  
\int d\mu 
\exp{(-\frac{1}{2} \frac{(x_i - \mu)^2}{\sigma_i^2})}
\exp{(-\frac{1}{2} \frac{(\mu - t)^2}{\sigma_t^2})}
$$

In the [last post](../../../../2018/12/10/normalization-of-product-of-two-gaussians/) I verified that the value of the integral is a Normal distribution, 

$$P(x_i|t) \sim N(t, \sqrt{\sigma_i^2 + \sigma_t^2})$$

$$P(x_i|t) = \frac{1}{\sqrt{2 \pi (\sigma_i^2 + \sigma_t^2)}}
\exp{(-\frac{1}{2} \frac{(x_i - t)^2}{\sigma_i^2 +\sigma_t^2})}
$$

## Estimate of population parameters with maximum likelihood

Given a set of observations of `$X$`, we can use the above expression to estimate the population parameters, `$t$` and `$\sigma_t$`. In this case teh overall likelihood is the product of the individual likelihoods,

$$ L = \Pi_i P(x_i | t)$$
Then the log-likelihood (actually -2 times the log-likelihood) is,

$$ l = - 2 \ln{L} = 
\Sigma_i 
\frac{(x_i - t)^2}{\sigma_i^2 +\sigma_t^2} + \Sigma_i \ln{(\sigma_i^2 +\sigma_t^2)}$$

The maximum likelihood values are determined by setting the first derivatives to 0 and solving for `$t$` and `$\sigma_t$`,

## value of t

$$ \frac{\partial l}{\partial t} = 2 \Sigma_i \frac{(t - x_i)}{\sigma_i^2 +\sigma_t^2}$$

$$ t = 
\frac{
\Sigma_i {x_i / (\sigma_i^2 +\sigma_t^2})
}
{\Sigma_i {1 / (\sigma_i^2 +\sigma_t^2)}
}$$

## value of `$\sigma_t$`

$$ 
\frac{\partial l}{\partial \sigma_t} = 
2 \sigma_t (
- \Sigma_i \frac{(t - x_i)^2}{(\sigma_i^2 +\sigma_t^2)^2} 
+ 
\Sigma_i {\frac{1}{\sigma_i^2 +\sigma_t^2}})$$

## solving the equations

These equations are coupled and non-linear so there's no closed form solution. However, we can investigate the limiting behavior in three interesting scenarios.

### All `$\sigma_i$` equal 

If `$\sigma_i = \sigma_x$` for all `$i$`, then these simplify to 

$$ t = \Sigma_i x_i $$

$$\frac{1}{(\sigma_x^2 +\sigma_t^2)^2} \Sigma_i (t - x_i)^2 = 
\frac{N}{\sigma_x^2 +\sigma_t^2}$$

$$ \sigma_t^2 = \frac{1}{N} \Sigma_i (t - x_i)^2 - \sigma_x^2$$

where `$N$` is the number of observations of `$X$`.

The result for `$\sigma_t$` says that the variance of the latent population is the sample variance minus the noise variance.

### `$\sigma_i \ll \sigma_t$`

In this limit the noise is negligible - each measurement very precisely measures the latent value, `$t$`. Then

$$ t = \Sigma_i x_i$$

$$ \sigma_t^2 = \frac{1}{N} \Sigma_i (t - x_i)^2$$, 

i.e. the variance of the latent variable, `$t$` is equal to the sample variance.

### `$\sigma_i \gg \sigma_t$`

This limit corresponds to the case where the noise is very large.  



